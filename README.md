
# ğŸ§  Deepfake Detection System

A Flask-based web application that uses a Convolutional Neural Network (CNN) to classify facial images as either **Real** or **Fake** (deepfake). Built using TensorFlow and OpenCV, the model was trained on a dataset of real and fake faces (~980MB) and deployed via a lightweight REST API.

---

## ğŸš€ Features

- âœ… Real-time image upload and prediction
- ğŸ§  Custom CNN model trained on preprocessed face images
- ğŸ“¦ REST API for classification (`/predict`)
- ğŸ“¸ Image preprocessing using OpenCV (resize, normalize)
- ğŸŒ Flask-based web interface for local or cloud deployment

---

## ğŸ§  Model Overview

- 3 Convolutional layers with ReLU activation and MaxPooling
- Dropout layers to prevent overfitting
- Fully connected Dense layer with Sigmoid output
- Trained using binary cross-entropy loss and Adam optimizer
- Achieved **~60% test accuracy** on a limited dataset

---

## ğŸ–¼ï¸ Web App Demo

Upload a face image via the UI or POST an image file to `/predict`.  
The server responds with a prediction: `"Real"` or `"Fake"`.

---

## ğŸ“ Folder Structure

```
deepfake-detector/
â”‚
â”œâ”€â”€ app.py                  # Flask backend + REST API
â”œâ”€â”€ model.py                # CNN training script
â”œâ”€â”€ prep-processing.py      # Data preprocessing script
â”œâ”€â”€ final_model.keras       # Trained model
â”œâ”€â”€ download_dataset.py     # Google Drive auto-download script
â”œâ”€â”€ dataset/                # Preprocessed .npy files (after extraction)
â”œâ”€â”€ Dataset/                # Raw images (if using original data)
â”œâ”€â”€ templates/              # index.html (upload form)
â”œâ”€â”€ static/                 # Uploaded images
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“¥ Dataset Setup

This project uses a preprocessed `.npy` dataset (~980MB), hosted on Google Drive.

### âœ… Prerequisites:
- Python 3.x
- `gdown` (installed via requirements)

### ğŸ“¦ Step 1: Install Requirements
```bash
pip install -r requirements.txt
```

Make sure your `requirements.txt` includes:
```
gdown
```

### ğŸš€ Step 2: Run the Download Script
```bash
python download_dataset.py
```

This will:
- Download `dataset.zip` (~980MB) from Google Drive
- Unzip it into your project root as:
```
./dataset/
â”œâ”€â”€ X_train.npy
â”œâ”€â”€ X_test.npy
â”œâ”€â”€ y_train.npy
â””â”€â”€ y_test.npy
```

âœ… Your training code will work out-of-the-box with this structure.

---

## ğŸ”— API Usage

**Endpoint:** `POST /predict`  
**Form Data:** `image` (file)  
**Returns:**
```json
{
  "prediction": "Fake",
  "image_path": "static/your_uploaded_image.jpg"
}
```

---

## ğŸ“Š Future Improvements

- Improve accuracy using transfer learning (e.g., MobileNetV2)
- Deploy on Render/Heroku for public access
- Add face detection and cropping before classification
- Add confidence score to the response

---

## ğŸ‘¨â€ğŸ’» Author

Rudraksh Mehra  
ğŸ“§ your-email@example.com  
ğŸ”— [LinkedIn](https://linkedin.com/in/yourprofile) | [GitHub](https://github.com/yourusername)
